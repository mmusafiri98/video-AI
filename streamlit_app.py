import streamlit as st
from PIL import Image
import torch
from diffusers import StableDiffusionImg2ImgPipeline
import imageio
import tempfile
import os

# ---------- CONFIG ----------
st.set_page_config(page_title="Video Generator CPU", page_icon="ğŸ¬", layout="centered")

st.title("ğŸ¬ GÃ©nÃ©rateur VidÃ©o CPU-friendly")

# ---------- Charger le modÃ¨le (open-source) ----------
@st.cache_resource
def load_model():
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float32
    )
    pipe.to("cpu")  # CPU uniquement
    return pipe

pipe = load_model()

# ---------- Upload d'image ----------
uploaded_file = st.file_uploader("ğŸ“¤ Uploade une image de dÃ©part", type=["png", "jpg", "jpeg"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Image de dÃ©part", use_container_width=True)

    prompt = st.text_input("ğŸ“ DÃ©cris la transformation Ã  appliquer", "Un paysage futuriste cyberpunk")
    num_frames = st.slider("â± Nombre de frames pour la vidÃ©o", 4, 12, 6)

    if st.button("ğŸš€ GÃ©nÃ©rer la vidÃ©o"):
        with st.spinner("GÃ©nÃ©ration en cours... â³ (CPU peut Ãªtre lent)"):
            frames = []
            for i in range(num_frames):
                # Chaque frame peut Ãªtre lÃ©gÃ¨rement diffÃ©rente si tu veux un effet animÃ©
                frame = pipe(prompt=prompt, image=image, strength=0.6, guidance_scale=7.5).images[0]
                frames.append(frame)

            # Sauvegarde en vidÃ©o
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, "output.mp4")
            imageio.mimsave(output_path, frames, fps=4)  # fps bas pour CPU

        st.success("âœ… VidÃ©o gÃ©nÃ©rÃ©e !")
        st.video(output_path)

