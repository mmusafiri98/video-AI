import streamlit as st
import torch
from diffusers import DiffusionPipeline

# Charger le modÃ¨le une seule fois (mise en cache Streamlit)
@st.cache_resource
def load_pipeline():
    pipe = DiffusionPipeline.from_pretrained(
        "stabilityai/stable-video-diffusion-img2vid",
        torch_dtype=torch.float16,
    )
    pipe = pipe.to("cuda" if torch.cuda.is_available() else "cpu")
    return pipe

st.title("ğŸ¬ GÃ©nÃ©rateur de VidÃ©o avec Diffusers")

# Upload image de dÃ©part
image_file = st.file_uploader("ğŸ“¤ Uploade une image de dÃ©part (PNG/JPG)", type=["png", "jpg", "jpeg"])

if image_file:
    from PIL import Image
    image = Image.open(image_file).convert("RGB")
    st.image(image, caption="Image de dÃ©part", use_container_width=True)

    # Bouton de gÃ©nÃ©ration
    if st.button("ğŸš€ GÃ©nÃ©rer la vidÃ©o"):
        pipe = load_pipeline()

        with st.spinner("GÃ©nÃ©ration en cours... â³"):
            video_frames = pipe(image, num_frames=16).frames

        # Sauvegarder la vidÃ©o temporairement
        import imageio
        output_path = "output.mp4"
        imageio.mimsave(output_path, video_frames, fps=8)

        st.video(output_path)
        st.success("âœ… VidÃ©o gÃ©nÃ©rÃ©e avec succÃ¨s !")



